{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验1：典型监督学习方法分类实践与比较分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 实验目的与要求\n",
    "1. 利用所学习的监督学习方法完成目标识别实验方案的设计。\n",
    "2. 编程并利用相关软件完成实验测试，得到实验结果。\n",
    "3. 通过对实验数据的分析, 整理, 方法的对比, 得出实验结论, 培养学生创新思维和编写实验报告的能力, 以及处理一般工程设计技术问题的初步能力及实事求是的科学态度。\n",
    "4. 利用实验更加直现、方便和易于操作的优势，提高学生学习兴趣，让学生自主发挥设计和实施实验，发挥学生潜在的积极性和创造性。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 实验主要内容\n",
    "1. 采用已经学过的监督学习的方法，如：逻辑回归、决策树、神经网络等实现分类任务。\n",
    "2. 分析比较不同方法的优缺点\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 数据源\n",
    "\n",
    "| 数据集特征 | 多变量 | 实例数  | 150  |    分区    |    life    |\n",
    "| :--------: | :----: | :-----: | :--: | :--------: | :--------: |\n",
    "|  属性特征  |  Real  | 属性数  |  4   |  捐赠日期  | 1988-07-01 |\n",
    "|  相关任务  |  分类  | 缺失值? |  无  | 网页点击数 |  4121103   |\n",
    "\n",
    "[数据源](http://archive.ics.uci.edu/ml/datasets/Iris)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集信息\n",
    "\n",
    "![20210729104905](https://i.loli.net/2021/07/29/Kp6qlL4hEf3aigb.png)\n",
    "\n",
    "This is perhaps the best known database to be found in the pattern recognition literature. Fisher's paper is a classic in the field and is referenced frequently to this day. (See Duda & Hart, for example.) The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other.\n",
    "\n",
    "这可能是模式识别文献中最著名的数据库。Fisher 的论文是该领域的经典之作，至今仍被频繁引用(例如，参见 Duda & Hart。）该数据集包含 3 个类别，每个类别 50 个实例，其中每个类别指的是一种鸢尾属植物。一类与另两类是线性可分的；后者不是线性可分离的。\n",
    "\n",
    "Predicted attribute: class of iris plant.    \n",
    "预测属性：鸢尾属植物类。\n",
    "\n",
    "This is an exceedingly simple domain.    \n",
    "这是一个非常简单的领域。\n",
    "\n",
    "This data differs from the data presented in Fishers article (identified by Steve Chadwick, spchadwick '@' espeedaz.net ). The 35th sample should be: 4.9,3.1,1.5,0.2,\"Iris-setosa\" where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,\"Iris-setosa\" where the errors are in the second and third features.\n",
    "\n",
    "该数据与 Fishers 文章中的数据不同（由 Steve Chadwick、spchadwick '@' espedaz.net确定）。第35个样本应为：4.9,3.1,1.5,0.2，“Iris setosa”，其中误差在第四个特征中。第38个样本：4.9,3.6,1.4,0.1，“Iris setosa”，其中错误出现在第二和第三个特征中。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 属性信息\n",
    "\n",
    "1. sepal length in cm    \n",
    "   萼片长度\n",
    "2. sepal width in cm    \n",
    "   萼片宽度\n",
    "3. petal length in cm      \n",
    "   花瓣长度 \n",
    "4. petal width in cm    \n",
    "   花瓣宽度\n",
    "5. class:      \n",
    "   类别    \n",
    "-- Iris Setosa  山鸢尾    \n",
    "-- Iris Versicolour  变色鸢尾    \n",
    "-- Iris Virginica  弗吉尼亚鸢尾    \n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逻辑回归\n",
    "\n",
    "- [温州大学《机器学习》课程课件（三）逻辑回归](https://zhuanlan.zhihu.com/p/361621889)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "\n",
    "### 分类问题\n",
    "\n",
    "#### 监督学习的最主要类型\n",
    "\n",
    "- 分类（Classification） \n",
    "\n",
    "  > 标签离散\n",
    "\n",
    "  - 身高1.85m，体重100kg的男人穿什么尺码的T恤？\n",
    "  - 根据肿瘤的体积、患者的年龄来判断良性或恶性？ \n",
    "  - 根据用户的年龄、职业、存款数量来判断信用卡是否会违约？\n",
    "\n",
    "> 输入变量可以是离散的，也可以是连续的\n",
    "\n",
    "---\n",
    "\n",
    "#### 二分类\n",
    "\n",
    "我们先从用蓝色圆形数据定义为类型1，其余数据为类型2；只需要分类1次\n",
    "\n",
    "步骤：① ->②\n",
    "\n",
    "![image-20210802081155852](http://cdn.ayusummer233.top/img/20210802081202.png)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### 多分类\n",
    "\n",
    "我们先定义其中一类为类型1（正类），其余数据为负类（rest）；\n",
    "\n",
    "接下来去掉类型1数据，剩余部分再次进行二分类，分成类型2和负类；\n",
    "\n",
    "如果有𝑛类，那就需要分类 𝑛-1 次\n",
    "\n",
    "步骤：① -> ② -> ③ -> ……\n",
    "\n",
    "![image-20210802081340700](http://cdn.ayusummer233.top/img/20210802081340.png)\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Sigmoid 函数\n",
    "\n",
    "𝜎(𝑧) 代表一个常用的逻辑函数（logistic function）, 为𝑆形函数（Sigmoid function）\n",
    "\n",
    "$\\sigma (z) = g(z) = \\frac{1}{1+e^{-z}}$\n",
    "\n",
    "$z=w^Tx+b$\n",
    "\n",
    "合起来，我们得到逻辑回归模型的假设函数：\n",
    "\n",
    "$L(\\hat{y}, y) = -y log\\hat{y} - (1-y) log(1- \\hat{y})$\n",
    "\n",
    "![](http://cdn.ayusummer233.top/img/20210802091615.png)\n",
    "\n",
    "当 $\\sigma(z) \\geq 0.5$​  时, 预测 $y=1$​\n",
    "\n",
    "当 $\\sigma(z) < 0.5$​​  时, 预测 $y=0$\n",
    "\n",
    "> 注意: 若表达式 $h(x) = z =  w_0 + w_1 x_1 + w_2 x_2 + ... + w_n x_n + b $​, 则 b 可以融入到 $w_0$​, 即: $z=w^Tx$​\n",
    "\n",
    "线性回归的函数 $h(x) = z = w^Tx$​, 范围是 $(−∞, +∞)$。\n",
    "\n",
    "而分类预测结果需要得到 $[0,1]$ 的概率值。\n",
    "\n",
    "在二分类模型中，事件的几率 odds：事件发生与事件不发生的概率之比为 $\\frac{p}{1-p}$, 称为事件的发生比（the odds of experiencing an event）\n",
    "\n",
    "其中𝑝为随机事件发生的概率，𝑝的范围为 $[0,1]$。\n",
    "\n",
    "取对数得到：$log \\frac{p}{1-p}$ 而 $log \\frac{p}{1-p} = w^T x = z$\n",
    "\n",
    "求解得到：$p = \\frac{1}{1+ e^{-w^T x}} = \\frac{1}{1+e^{-z}}$​\n",
    "\n",
    "将 𝑧 进行逻辑变换: $g(z) = \\frac{1}{1+e^{-z}}$\n",
    "\n",
    "$g'(z) = (\\frac{1}{1+e^{-z}})' \\\\ = \\frac{e^{-z}}{(1+e^{-z})^2} \\\\ = \\frac{1 + e^{-z} - 1}{(1+e^{-z})^2} \\\\ = \\frac{1}{(1 + e^{-z})}(1 - \\frac{1}{1 + e^{-z}}) \\\\ = g(z)(1 - g(z))$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 逻辑回归求解\n",
    "\n",
    "假设一个二分类模型： \n",
    "\n",
    "$p(y = 1|x; w) = h(x)$\n",
    "\n",
    "$p(y=0|x;w) = 1-h(x)$\n",
    "\n",
    "则: $p(y|x;w) = (h(x))^y(1-h(x))^{1-y}$​\n",
    "\n",
    "逻辑回归模型的假设是: $h(x)=g(w^Tx)=g(z)$\n",
    "\n",
    "其中 $z = w^Tx$​, 逻辑函数 (logistic function) 公式为:\n",
    "\n",
    "$g(z)=\\frac{1}{1+e^{-z}}, g'(z)=g(z)(1-g(z))$\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### 损失函数\n",
    "\n",
    "$L(\\hat{y}, y) = -y log(\\hat{y}) - (1-y)log(1-\\hat{y})$\n",
    "\n",
    "为了衡量算法在全部训练样本上的表现如何, 我们需要定义一个算法的代价函数, 算法的代价函数是对 m 个样本的损失函数求和然后除以 m:\n",
    "\n",
    "---\n",
    "\n",
    "#### 代价函数\n",
    "\n",
    "$J(w) = \\frac{1}{m} \\sum_{i=1}^m L(\\hat{y}^{(i)}, y^{(i)}) = \\frac{1}{m} \\sum_{i=1}^m {( -y^{(i)} log(\\hat{y}^{(i)}) - (1-y^{(i)})log(1-\\hat{y}^{(i)}) )}$\n",
    "\n",
    "---\n",
    "\n",
    "#### 求解过程\n",
    "\n",
    "似然函数为: \n",
    "\n",
    "$L(w) = \\prod_{i=1}^m{P(y^{(i)} | x^{(i)}; w)} = \\prod_{i=1}^m{ (h(x^{(i)}))^{y^{(i)}} (1 - h(x^{(i)}))^{1-y^{(i)}}}$\n",
    "\n",
    "似然函数两边取对数, 则连乘号变成了连加号:\n",
    "\n",
    "$l(w) = log L(w) = \\sum_{i=1}^m{( y^{(i)} log( h(x^{(i)}) ) + (1 - y^{(i)}) log(1 - h(x^{(i)}))    )}$\n",
    "\n",
    "代价函数为:\n",
    "\n",
    "$J(w) = - \\frac{1}{m} l(w) = - \\frac{1}{m} \\sum_{i=1}^m{( y^{(i)} log( h(x^{(i)}) ) + (1 - y^{(i)}) log(1 - h(x^{(i)}))    )}$\n",
    "\n",
    "> [统计学](https://baike.baidu.com/item/统计学/1175)中，似然函数是一种关于[统计模型](https://baike.baidu.com/item/统计模型/7492984)参数的[函数](https://baike.baidu.com/item/函数/301912)。给定输出x时，关于参数θ的似然函数L(θ|x)（在数值上）等于给定参数θ后变量X的概率：L(θ|x)=P(X=x|θ)。\n",
    ">\n",
    "> 似然函数在[推断统计学](https://baike.baidu.com/item/推断统计学/10416457)（Statistical inference）中扮演重要角色，尤其是在参数估计方法中。在教科书中，似然常常被用作“概率”的同义词。但是在统计学中，二者有截然不同的用法。概率描述了已知参数时的随机变量的输出结果；似然则用来描述已知[随机变量](https://baike.baidu.com/item/随机变量/828980)输出结果时，未知参数的可能取值。例如，对于“一枚正反对称的硬币上抛十次”这种事件，我们可以问硬币落地时十次都是正面向上的“概率”是多少；而对于“一枚硬币上抛十次”，我们则可以问，这枚硬币正反面对称的“似然”程度是多少。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "-----\n",
    "\n",
    "### 逻辑回归代码实现\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d36b7e63cb0f63afce68fe5c49ec0e1190f861a688b361cec73da19541843943"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('MachineLearning': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
