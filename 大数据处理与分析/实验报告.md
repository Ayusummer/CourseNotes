# 大数据分析与处理

## 课程实验目的与要求

### 实验目的

熟悉 `CloudStack`, `Hadoop` 的安装与使用, 会编写 `MapReduce` 程序

---

### 实验要求

- 安装虚拟机和 Linux
- 安装 CloudStack
- 安装 Hadoop 并测试其性能
- 编写并运行一个 MapReduce 程序

---

## 课程实验内容

- 安装虚拟机和 Linux
- 安装 CloudStack
- 安装 Hadoop 并测试其性能
- 编写并运行一个 MapReduce 程序

---

## 课程实验设备与环境

- `腾讯云轻量(上海)` + `CentOS 7.6` + `CloudStack 4.15.2`
- `Win11(dev)` + `WSL 2` + `Ubuntu 18.04 LTS` + `VSCode + Remote-WSL + Terminal` + `java-11-openjdk-amd64` + `hadoop-3.3.0` + `python3.8.0`

---

## 设计正文

---

### 分析与设计思路

略

---

### 各模块流程图

> [关于cloudstack，openstack，kubernetes三个开源云平台的架构演进思考 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/49523193)
>
> [Kubernetes（k8s）中文文档 Kubernetes概述_Kubernetes中文社区](https://www.kubernetes.org.cn/k8s)
>
> [CloudStack 简介 - Jamin Zhang](https://jaminzhang.github.io/cloud-computing/CloudStack-Introduction/)

---

CloudStack 是一个 IaaS 级的服务，IaaS 提供了对资源的自动化管理能力。 例如用界面、脚本甚至 Web Service API 实现对大量硬件、大量虚拟机的生命周期管理。
IaaS 产品面对的是大规模、可伸缩的云环境，这是与用手工管理有限资源的方式完全不同的一类系统。

- CloudStack 是一个开源的具有高可用性及扩展性的云计算平台。
- CloudStack 是一个开源的云操作系统，它可以帮助用户利用自己的硬件提供类似于 Amazon EC2 那样的公共云服务。
- CloudStack 可以通过组织和协调用户的虚拟化资源，构建一个和谐的环境。
- Cloudstack 支持管理大部分主流的 hypervisors(管理程序)，如 KVM，XenServer，VMware，Oracle VM，Xen 等。

> KVM(Kernel-based Virtual Machine 的简称，是一个开源的[系统虚拟化](https://baike.baidu.com/item/系统虚拟化)模块，自 Linux 2.6.20 之后集成在 Linux 的各个主要发行版本中。它使用 [Linux](https://baike.baidu.com/item/Linux/27050) 自身的调度器进行管理，所以相对于 [Xen](https://baike.baidu.com/item/Xen)，其核心源码很少。KVM 已成为学术界的主流 [VMM](https://baike.baidu.com/item/VMM) 之一。)

Cloudstack 部署架构:

![CloudStack-Architecture-and-Concepts](http://cdn.ayusummer233.top/img/202109150948407.png)

![region-overview](http://cdn.ayusummer233.top/img/202109150949283.png)

- `Zone`

  Zone 对应于现实中的一个数据中心，它是 CloudStack 中最大的一个单元。
  即从包含关系上来说，一个 Zone 包含多个 Pod，一个 Pod 包含多个 Cluster，一个 Cluster 包含多个 Host。
  
- `Pod` 提供点

  一个提供点通常代表一个机柜，机柜里面的主机在同一个子网，每个区域中必须包含一个或多个提供点，提供点中包含主机和主存储服务器，CloudStack 的内部管理通信配置一个预留 IP 地址范围。预留的 IP 范围对云中的每个区域来说必须唯一。
  
- `Cluster` 集群

  Cluster 是多个主机组成的一个集群。
  同一个 Cluster 中的主机有相同的硬件，相同的 Hypervisor(管理程序/管理员)，和共用同样的存储。
  同一个 Cluster 中的虚拟机，可以实现无中断服务地从一个主机迁移到另外一个上。
  集群由一个或多个宿主机和一个或多个主要存储服务器构成。
  集群的大小取决于下层虚拟机软件。大多数情况下基本无建议。
  当使用 VMware 时，每个 VMware 集群都被 vCenter 服务器管理。
  管理员必须在本产品中登记 vCenter。每个 Zone 下可以有多个 vCenter 服务器。每个 vCenter 服务器可能管理多个 VMware 集群。
  
- `Host` 主机

  Host 就是运行的虚拟机（VM）主机。

  宿主机就是个独立的计算机。宿主机运行来宾虚拟机并提供其相应的计算资源。
  每个宿主机都装有虚拟机软件来运行来宾虚拟机。
  比如一个开启了 kvm 支持的服务器，一个思杰 XenServer 服务器，或者一个 ESXi 服务器都可以作为宿主机。
  宿主机在 CloudStack 部署中属于最小的组织单元。
  宿主机包含于集群中，集群又属于提供点，而区域中包含提供点（就是在逻辑概念上 Zone>Pod>Cluster>Host ），
  新增的宿主机可以随时添加以提供更多资源给来宾虚拟机，CloudStack 自动探测宿主机的 CPU 数量和内存资源。
  宿主机对终端用户不可见。终端用户不能决定他们的虚拟机被分配到哪台宿主机。
  
- `Primary Storage` 一级存储

  一级存储与 Cluster 关联，它为该 Cluster 中的主机的全部虚拟机提供磁盘卷。一个 Cluster 至少有一个一级存储，且在部署时位置要临近主机以提供高性能。
  
- `Secondary Storage` 二级存储

  二级存储与 Zone 关联，它存储模板文件，ISO 镜像和磁盘卷快照。

---


- Hadoop 的核心，说白了，就是 HDFS 和 MapReduce。HDFS 为海量数据提供了**存储**，而 MapReduce 为海量数据提供了**计算框架**。

  ![img](http://cdn.ayusummer233.top/img/202110241452093.jpeg)

#### **HDFS**


- HDFS 有三个重要角色：**NameNode**（名称节点）、**DataNode**（数据节点）和**Client**（客户机）。

  ![img](http://cdn.ayusummer233.top/img/202110241453247.jpeg)

  **NameNode：**是 Master 节点（主节点），可以看作是分布式文件系统中的管理者，主要负责管理文件系统的命名空间、集群配置信息和存储块的复制等。NameNode 会将文件系统的 Meta-data 存储在内存中，这些信息主要包括了文件信息、每一个文件对应的文件块的信息和每一个文件块在 DataNode 的信息等。

  **DataNode：**是 Slave 节点（从节点），是文件存储的基本单元，它将 Block 存储在本地文件系统中，保存了 Block 的 Meta-data，同时周期性地将所有存在的 Block 信息发送给 NameNode。

  **Client：**切分文件；访问 HDFS；与 NameNode 交互，获得文件位置信息；与 DataNode 交互，读取和写入数据。 

  **Block（块）**：Block 是 HDFS 中的基本读写单元；HDFS 中的文件都是被切割为 block（块）进行存储的；这些块被复制到多个 DataNode 中；块的大小（通常为 64 MB）和复制的块数量在创建文件时由 Client 决定。

- **HDFS** 的写入流程

  ![img](http://cdn.ayusummer233.top/img/202110241457573.jpeg)

  1. 用户向 Client（客户机）提出请求。例如，需要写入 200 MB 的数据。
  2. Client 制定计划：将数据按照 64 MB 为块，进行切割；所有的块都保存三份。
  3. Client 将大文件切分成块（block）。
  4. 针对第一个块，Client 告诉 NameNode（主控节点），请帮助我，将 64 MB 的块复制三份。
  5. NameNode 告诉 Client 三个 DataNode（数据节点）的地址，并且将它们根据到 Client 的距离，进行了排序。
  6. Client 把数据和清单发给第一个 DataNode。
  7. 第一个 DataNode 将数据复制给第二个 DataNode。
  8. 第二个 DataNode 将数据复制给第三个 DataNode。
  9. 如果某一个块的所有数据都已写入，就会向 NameNode 反馈已完成。
  10. 对第二个 Block，也进行相同的操作。
  11. 所有 Block 都完成后，关闭文件。NameNode 会将数据持久化到磁盘上。

- **HDFS** 读取流程(简化描述)

  ![img](http://cdn.ayusummer233.top/img/202110241502137.jpeg)

  1. 用户向 Client 提出读取请求。
  2. Client 向 NameNode 请求这个文件的所有信息。
  3. NameNode 将给 Client 这个文件的块列表，以及存储各个块的数据节点清单（按照和客户端的距离排序）。
  4. Client 从距离最近的数据节点下载所需的块。
  
  
  

---

### 主要算法源码

`mapper.py`

```python
#!/usr/bin/env python
# encoding=utf-8
import sys
txt = []
for line in sys.stdin:
    line = line.strip()
    words = line.split()
    for word in words:
        print(word)
```

`reduce.py`

```python
#!/usr/bin/env python
# encoding=utf-8
from operator import itemgetter
import sys

current_word = None
current_count = 0
word = None
 
for line in sys.stdin:
    line = line.strip()
    asum = 0
    if line != "":
        try:
            asum += int("".join(list(filter(str.isdigit, line))))
        except:
            pass
    print(asum)

```

---

### 改进或拓展(若有则重点用一小节进行说明)

使用 Python 编写 MapReduce 程序实现了一个过滤 hdfs 文件中的数值的程序

具体算法见上一节主要算法源码

---

## 课程实验结果与分析

### 2

![image-20211106212154566](http://cdn.ayusummer233.top/img/202111062122029.png)

![image-20211106212232116](http://cdn.ayusummer233.top/img/202111062122523.png)

![image-20211106212312774](http://cdn.ayusummer233.top/img/202111062123176.png)

---

### Hadoop

![image-20211106212514824](http://cdn.ayusummer233.top/img/202111062125149.png)

![image-20211106212535462](http://cdn.ayusummer233.top/img/202111062125752.png)

![image-20211106212600297](http://cdn.ayusummer233.top/img/202111062126725.png)

![image-20211106212746462](http://cdn.ayusummer233.top/img/202111062127992.png)

![image-20211106212814629](http://cdn.ayusummer233.top/img/202111062128064.png)

![image-20211106212849463](http://cdn.ayusummer233.top/img/202111062128772.png)

![image-20211106212921289](http://cdn.ayusummer233.top/img/202111062129583.png)





---

### TestDFSIO

```shell
hadoop jar hadoop-mapreduce-client-jobclient-3.0.0-tests.jar TestDFSIO -write -nrFiles 5 -size 10MB
```

![image-20211106213129896](http://cdn.ayusummer233.top/img/202111062131230.png)

![image-20211106213202596](http://cdn.ayusummer233.top/img/202111062132792.png)

`TestDFSIO_results.log`

```sh
----- TestDFSIO ----- : write
            Date & time: Sat Nov 06 21:30:34 CST 2021
        Number of files: 5
 Total MBytes processed: 50
      Throughput mb/sec: 34.99
 Average IO rate mb/sec: 56.99
  IO rate std deviation: 41
     Test exec time sec: 4.03

```

![image-20211106213258171](http://cdn.ayusummer233.top/img/202111062132318.png)

---

`读操作`:

```shell
root@咸鱼型233のPC:/home/ayusummer/Hadoop/hadoop-3.3.0/share/hadoop/mapreduce# hadoop jar hadoop-mapreduce-client-jobclient-3.3.0-tests.jar TestDFSIO  -read -nrFiles 5 -size 10MB
```

![image-20211106213514338](http://cdn.ayusummer233.top/img/202111062135664.png)

![image-20211106213531612](http://cdn.ayusummer233.top/img/202111062135760.png)

`TestDFSIO_results.log`:

```sh
----- TestDFSIO ----- : write
            Date & time: Sat Nov 06 21:30:34 CST 2021
        Number of files: 5
 Total MBytes processed: 50
      Throughput mb/sec: 34.99
 Average IO rate mb/sec: 56.99
  IO rate std deviation: 41
     Test exec time sec: 4.03

----- TestDFSIO ----- : read
            Date & time: Sat Nov 06 21:34:21 CST 2021
        Number of files: 5
 Total MBytes processed: 50
      Throughput mb/sec: 303.03
 Average IO rate mb/sec: 348.73
  IO rate std deviation: 109.92
     Test exec time sec: 2.96

```

![image-20211107081951811](http://cdn.ayusummer233.top/img/202111070819960.png)

---

### mrbench

- mrbench 会多次重复执行一个小作业
  用于检查在机群上小作业的运行是否可重复以及运行是否高效

- 使用 3 个 mapper 和 3 个 reducer 运行一个小作业 20 次，生成输入行数为 5，降序排列

```shell
root@咸鱼型233のPC:/home/ayusummer/Hadoop/hadoop-3.3.0/share/hadoop/mapreduce# hadoop jar hadoop-mapreduce-client-jobclient-3.3.0-tests.jar mrbench -numRuns 20 -maps 3 -reduces 3 -inputLines 5 -inputType descending
```

![image-20211106213848404](http://cdn.ayusummer233.top/img/202111062138786.png)

### nnbench

- 测试 NameNode 的负载
  这个测试能在 HDFS 上创建、读取、重命名和删除文件操作
- 使用 3 个 mapper 和 3 个 reducer 来创建 100 个文件

```sh
root@咸鱼型233のPC:/home/ayusummer/Hadoop/hadoop-3.3.0/share/hadoop/mapreduce# hadoop jar hadoop-mapreduce-client-jobclient-3.3.0-tests.jar nnbench -operation create_write -maps 3 -reduces 3 -numberOfFiles 100 -replicationFactorPerFile 3 -readFileAfterOpen true
```

![image-20211106214233897](http://cdn.ayusummer233.top/img/202111062142367.png)

![image-20211106214644271](http://cdn.ayusummer233.top/img/202111062146760.png)

`NNBench_results.log`:

```sh
-------------- NNBench -------------- : 
                               Version: NameNode Benchmark 0.4
                           Date & time: 2021-10-25 18:00:46,35

                        Test Operation: create_write
                            Start time: 2021-10-25 18:00:38,295
                           Maps to run: 3
                        Reduces to run: 3
                    Block Size (bytes): 1
                        Bytes to write: 0
                    Bytes per checksum: 1
                       Number of files: 100
                    Replication factor: 3
            Successful file operations: 0

        # maps that missed the barrier: 0
                          # exceptions: 3000

               TPS: Create/Write/Close: 0
Avg exec time (ms): Create/Write/Close: Infinity
            Avg Lat (ms): Create/Write: NaN
                   Avg Lat (ms): Close: NaN

                 RAW DATA: AL Total #1: 0
                 RAW DATA: AL Total #2: 0
              RAW DATA: TPS Total (ms): 7209
       RAW DATA: Longest Map Time (ms): 7300.0
                   RAW DATA: Late maps: 0
             RAW DATA: # of exceptions: 3000

-------------- NNBench -------------- : 
                               Version: NameNode Benchmark 0.4
                           Date & time: 2021-11-06 21:46:21,148

                        Test Operation: create_write
                            Start time: 2021-11-06 21:46:03,674
                           Maps to run: 3
                        Reduces to run: 3
                    Block Size (bytes): 1
                        Bytes to write: 0
                    Bytes per checksum: 1
                       Number of files: 100
                    Replication factor: 3
            Successful file operations: 0

        # maps that missed the barrier: 0
                          # exceptions: 3000

               TPS: Create/Write/Close: 0
Avg exec time (ms): Create/Write/Close: Infinity
            Avg Lat (ms): Create/Write: NaN
                   Avg Lat (ms): Close: NaN

                 RAW DATA: AL Total #1: 0
                 RAW DATA: AL Total #2: 0
              RAW DATA: TPS Total (ms): 16101
       RAW DATA: Longest Map Time (ms): 16281.0
                   RAW DATA: Late maps: 0
             RAW DATA: # of exceptions: 3000


```

---

### MapReduce

`test1.txt`:

```txt
aaa12
bbb34
aaa56
bbb67
ddd78
ccc32
ddd32
```

`test2.txt`

```txt
aaa55
bbb77
aaa55
bb33
ddd733
ccc89
ddd32
```

`run.sh`

```shell
hadoop jar /home/ayusummer/Hadoop/hadoop-3.3.0/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar \
-file /home/ayusummer/Mydocs/py/mapper.py       -mapper /home/ayusummer/Mydocs/py/mapper.py \
-file /home/ayusummer/Mydocs/py/reduce.py       -reducer /home/ayusummer/Mydocs/py/reduce.py \
-input /tmp/py/input/*  -output /tmp/py/output
```

```sh
root@咸鱼型233のPC:/home/ayusummer/Mydocs/py# ./run.sh
```

![image-20211106215706340](http://cdn.ayusummer233.top/img/202111062157621.png)

![image-20211106215818059](http://cdn.ayusummer233.top/img/202111062158529.png)

```sh
# 查看输出文件夹
root@咸鱼型233のPC:/home/ayusummer/Mydocs/py# hadoop fs -ls /tmp/py/output
# 查看输出文件
root@咸鱼型233のPC:/home/ayusummer/Mydocs/py# hadoop fs -cat /tmp/py/output/part-00000
```

![image-20211106215938790](http://cdn.ayusummer233.top/img/202111062159079.png)

有效地过滤出了 hdfs 文件中的整数

---

## 总结与进一步改进设想(选择 PPT 中给出的一个题目)

### 第一台公认的电子计算机是什么?

> [第一台电子计算机是ABC还是科洛萨斯？为什么都叫做第一台电子计算机？ - 知乎 (zhihu.com)](https://www.zhihu.com/question/63634242/answer/1004698650)

ABC 计算机（1942 年）这台机器是由 John Vincent Atanasoff 和 Clifford Berry 制造的，所以被命名为 Atanasoff–Berry Computer，简称 ABC 计算机，它被用于寻找线性方程组的解。这是第一个使用二进制来表示数据，通过电子开关来代替机械的计算机，但这台机器无法编程。

---

### 谈谈对大数据的看法

 随着互联网技术的不断更新迭代与普及,越来越多的人接入了互联网,并且随着越来越多的行为事件信息化,互联网上的数据量不断膨胀，相应地越来越多的人投入到如何有效地处理和利用这些数据以及相关的衍生问题上，“大数据”技术应运而生并持续升温。

“十三五”时期，我国大数据产业取得了突破性的发展。大数据产业规模持续稳步提升，产业价值不断释放；大数据相关政策陆续出台，产业发展环境日益优化；新型数据中心、5G等大数据相关基础设施部署进程加快；大数据企业快速成长，培育和发展了一批有竞争力的创新型企业； 

大数据产业是以数据采集、交易、存储、加工、分析、服务为主的各类经济活动，包括数据资源建设、大数据软硬件产品的开发、销售和租赁活动，以及相关信息技术服务。整体看，基础设施、数据服务、融合应用是大数据产业的三大组成部分，三者相互交融，形成完整的大数据产业生态。

---

### MapReduce 和传统方法的区别



---

### MapReduce 有哪些问题?

> [MapReduce优缺点_Daniel_Dictator的博客-CSDN博客_mapreduce优势](https://blog.csdn.net/Daniel_Dictator/article/details/102809964)

- MapReduce不擅长做实时计算、流式计算、DAG（有向图）计算。
  - `实时计算`: MapReduce无法像Mysql一样，在毫秒或者秒级内返回结果。
  - `流式计算`: 流式计算的输入数据是动态的，而 MapReduce 的输入数据集是静态的，不能动态变化。这是因为 MapReduce 自身的设计特点决定了数据源必须是静态的。
  - `DAG（有向图）计算`: 多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情况下，MapReduce 并不是不能做，而是使用后，每个 MapReduce 作业的输出结果都会写入到磁盘，会造成大量的磁盘 IO，导致性能非常的低下。

---

### 你有什么新的方法么?





---

## 参考文献







