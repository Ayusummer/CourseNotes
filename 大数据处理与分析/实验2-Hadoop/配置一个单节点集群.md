# 配置一个单节点集群(个人搭建记录)

[官方文档: Apache Hadoop 3.3.1 – Hadoop: Setting up a Single Node Cluster.](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html)[Apache Hadoop 3.3.1 – Hadoop: Setting up a Single Node Cluster.](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html)

---

## 目的

搭建并配置一个 `single-node(单节点) Hadoop`  以便快速使用 Hadoop MapReduce 及 HDFS执行一些简单的操作

参考文档为官网 `3.3.1` 版本的文档

---

## 先决条件

### 搭建环境

`Win11(dev) + WSL2 + Ubuntu 20.04 LTS + VSCode + Remote-SSH(VSCode扩展) + Terminal(VSCode扩展)`

![image-20211024184047856](http://cdn.ayusummer233.top/img/202110241840353.png)

![image-20210920183032515](http://cdn.ayusummer233.top/img/202110241842705.png)

![image-20211024184349173](http://cdn.ayusummer233.top/img/202110241843423.png)

![image-20211024184748477](http://cdn.ayusummer233.top/img/202110241847999.png)

---

### 需要安装的软件

1. java

   > [Hadoop Java Versions - Hadoop - Apache Software Foundation](https://cwiki.apache.org/confluence/display/HADOOP/Hadoop+Java+Versions)
   >
   > Hadoop 3.3 及更新的版本支持 Java8 和 Java11(**仅运行**)
   >
   > 请使用 Java 8 编译 Hadoop; 目前暂不支持 Java 11 编译 Hadoop

   由于 Oracle Java收费所以安装 OpenJDK

   ```shell
   sudo apt install openjdk-8-jdk
   ```

   

   > [Ubuntu 18.04 安装java8 - 花落未殇 - 博客园 (cnblogs.com)](https://www.cnblogs.com/zzy1024/p/11406269.html)
   >
   > ![image-20211024190319975](http://cdn.ayusummer233.top/img/202110241903087.png)
   >
   > `Failed to fetch 接 404 错误`
   >
   > 又试了下 java 11, 结果畅通无阻😅
   >
   > ![image-20211024192048679](http://cdn.ayusummer233.top/img/202110241920778.png)
   >
   > Java 11 是 Java 的一个长期支持版本（LTS）。它同时也是 Ubuntu 20.04的默认 Java 开发和运行环境。
   >
   > Java 8，前一个 Java LTS 版本，目前仍被广泛应用。
   >
   > 更新下源
   >
   > ```shell
   > apt update
   > ```
   >
   > ![image-20211024192347636](http://cdn.ayusummer233.top/img/202110241923871.png)
   >
   > 再使用如下命令安装 java 8 ,然后成功了😅
   >
   > ```shell
   > apt install openjdk-8-jdk
   > ```
   >
   > ![image-20211024192700851](http://cdn.ayusummer233.top/img/202110241927959.png)
   >
   > 那么此时我的 `ubuntu 20.04` 中有两个 java, 编译 Hadoop 需要 Java 8, 当前默认的是 java 11, 所以需要更改默认版本
   >
   > ```shell
   > sudo update-alternatives --config java
   > ```
   >
   > ![image-20211024193029622](http://cdn.ayusummer233.top/img/202110241930723.png)
   >
   > ![image-20211024193457195](http://cdn.ayusummer233.top/img/202110241934341.png)

   在一些 Java 应用中, 环境变量 `JAVA_HOME` 被用来表示 Java 安装位置

   上一步中使用 `sudo update-alternatives --config java` 看到了各版本 java 的安装位置

   ```shell
     Selection    Path                                            Priority   Status
   ------------------------------------------------------------
     0            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      auto mode
     1            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      manual mode
   * 2            /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java   1081      manual mode
   ```

   然后打开 `/etc/environment` 文件添加 `JAVA_HOME`

   ![image-20211024194431375](http://cdn.ayusummer233.top/img/202110241944436.png)

   重载环境变量

   ```shell
   source /etc/environment
   ```

   查看 `JAVA_HOME` 生效情况

   ```shell
   echo $JAVA_HOME
   ```

   ![image-20211024194542257](http://cdn.ayusummer233.top/img/202110241945329.png)

   > [如何在 Ubuntu 20.04 上安装 Java - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/137114682)
   >
   > 可以使用 `apt remove` 命令卸载相应版本 java

---

2. SSH 必须安装

![image-20211024195027098](http://cdn.ayusummer233.top/img/202110241950309.png)

---

### 安装软件

安装 `ssh` 和 `pdsh`

```shell
sudo apt-get install ssh
sudo apt-get install pdsh
```

> ![image-20211024195241497](http://cdn.ayusummer233.top/img/202110241952019.png)
>
> ![image-20211024195311555](http://cdn.ayusummer233.top/img/202110241953340.png)

---

## 下载

从 [Hadoop 3.3.1 的镜像站]([Index of /hadoop/common/hadoop-3.3.1 (apache.org)](https://dlcdn.apache.org/hadoop/common/hadoop-3.3.1/))获取稳定的发行版

![image-20211024200422270](http://cdn.ayusummer233.top/img/202110242004180.png)

AArch64 是 ARMv8 的一种执行状态

本地电脑是 amd64 架构的, 不能用那个包

![image-20211024200916933](http://cdn.ayusummer233.top/img/202110242012238.png)

> [【CPU】关于x86、x86_64/x64、amd64和arm64/aarch64 - 简书 (jianshu.com)](https://www.jianshu.com/p/2753c45af9bf)

> 打算放到 `root/Hadoop` 目录下:
>
> ![image-20211024201716352](http://cdn.ayusummer233.top/img/202110242017511.png)
>
> IDM 还挺快的, 不过速度基本维持在 1M 左右, 直接使用 `wget` 命令从文件地址下载倒快了很多
>
> ![image-20211024201843596](http://cdn.ayusummer233.top/img/202110242018666.png)

---

## 准备启动 Hadoop Cluster

解压缩下载的压缩包

```shell
tar -xf hadoop-3.3.1.tar.gz
```

> ![image-20211024202357274](http://cdn.ayusummer233.top/img/202110242023871.png)

打开解压后的文件夹中的 `etc/hadoop/hadoop-env.sh` 文件, 定义如下参数:

```shell
 # set to the root of your Java installation
 export JAVA_HOME=/usr/java/latest
```

其实[上一步](#需要安装的软件)已经设置了环境变量 JAVA_HOME, 不过在这里设定为项目参数的话也可以

![image-20211024213941363](http://cdn.ayusummer233.top/img/202110242139488.png)

`cd` 到解压缩文件夹根目录再执行 `bin/hadoop`

```shell
cd Hadoop/hadoop-3.3.1
bin/hadoop
```

![image-20211024214152222](http://cdn.ayusummer233.top/img/202110242141351.png)

可以看到 Hadoop 的使用文档

到此为止已经准备好了在三种支持模式之一启动 Hadoop Cluster

- [本地(独立)模式  Local (Standalone) Mode](#独立操作)
- [伪分布模式  Pseudo-Distributed Mode](#伪分布式操作)
- [全分布式模式 Fully-Distributed Mode](#全分布式操作)

---

## 独立操作

默认情况下, Hadoop 被配置为以 non-distributed 模式运行, 作为单个 java 进程. 这样调试比较方便

---

## 伪分布式操作

Hadoop 可以在单节点上以一种伪分布式的模式运行, 其中每个 Hadoop daemon 以一个单独的 java 进程运行

---

### 配置

使用如下配置文件:

`etc/Hadoop/core-site.xml`

```xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
</configuration>
```

![image-20211024221117826](http://cdn.ayusummer233.top/img/202110242211948.png)

`etc/hadoop/hdfs-site.xml`

```xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
</configuration>
```

![image-20211024221228547](http://cdn.ayusummer233.top/img/202110242212529.png)

---

### 配置无密码 SSH

现在检查下是否可以不用密码 ssh 上 localhost

```shell
ssh localhost
```

我现在的状态就是通过 SSH 连接的 WSL, 22 端口被占用, 所以这里有些意义不明

---

### 执行

以下是本地运行 MapReduce 作业

#### 1.格式化文件系统

在 Hadoop 解压文件夹根目录下运行

```shell
bin/hdfs namenode -format
```

![image-20211024222114432](http://cdn.ayusummer233.top/img/202110242221127.png)

![image-20211024222152831](http://cdn.ayusummer233.top/img/202110242221957.png)

---

#### 2.启动 NameNode daemon 和 DataNode daemon

```shell
sbin/start-dfs.sh
```

![image-20211024222740643](http://cdn.ayusummer233.top/img/202110242227516.png)

不能以 root 身份操作, enmmm, 那就再创建一个普通用户(remote-wsl默认以 root 权限登入导致我不记得默认的普通用户的账户了)

> [为Ubuntu系统添加新的普通用户_MeowingCat-CSDN博客_ubuntu创建普通用户](https://blog.csdn.net/MeowingCat/article/details/84134449)

```shell
useradd -m ubuntu -s /bin/bash
passwd ubuntu
sudo adduser ubuntu sudo
groups meow
usermod -aG sudo meow
visudo
su ubuntu
```

- 创建了可以登陆的 ubuntu 用户并使用 `/bin/bash` 作为 shell
- 设置密码
- 赋予 ubuntu 管理员权限
- 查看 ubuntu 所在的组。
- 设置 ubuntu 权限为 superuser。
- 查看 sudoer 的文本文件，可以添加 ubuntu ALL=(ALL:ALL) ALL为 ubuntu 设置superuser权限。
- 切换到 ubuntu 账户

![image-20211024224717334](http://cdn.ayusummer233.top/img/202110242247559.png)





---

### 单个节点上的 YARN

略

---

## 全分布式操作

略

