# 配置一个单节点集群(个人搭建记录)

[官方文档: Apache Hadoop 3.3.1 – Hadoop: Setting up a Single Node Cluster.](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html)[Apache Hadoop 3.3.1 – Hadoop: Setting up a Single Node Cluster.](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html)

---

## 目的

搭建并配置一个 `single-node(单节点) Hadoop`  以便快速使用 Hadoop MapReduce 及 HDFS执行一些简单的操作

参考文档为官网 `3.3.1` 版本的文档

---

## 先决条件

### 搭建环境

`Win11(dev) + WSL2 + Ubuntu 20.04 LTS + VSCode + Remote-SSH(VSCode扩展) + Terminal(VSCode扩展)`

![image-20211024184047856](http://cdn.ayusummer233.top/img/202110241840353.png)

![image-20210920183032515](http://cdn.ayusummer233.top/img/202110241842705.png)

![image-20211024184349173](http://cdn.ayusummer233.top/img/202110241843423.png)

![image-20211024184748477](http://cdn.ayusummer233.top/img/202110241847999.png)

---

### 需要安装的软件

1. java

   > [Hadoop Java Versions - Hadoop - Apache Software Foundation](https://cwiki.apache.org/confluence/display/HADOOP/Hadoop+Java+Versions)
   >
   > Hadoop 3.3 及更新的版本支持 Java8 和 Java11(**仅运行**)
   >
   > 请使用 Java 8 编译 Hadoop; 目前暂不支持 Java 11 编译 Hadoop

   由于 Oracle Java收费所以安装 OpenJDK

   ```shell
   sudo apt install openjdk-8-jdk
   ```

   

   > [Ubuntu 18.04 安装java8 - 花落未殇 - 博客园 (cnblogs.com)](https://www.cnblogs.com/zzy1024/p/11406269.html)
   >
   > ![image-20211024190319975](http://cdn.ayusummer233.top/img/202110241903087.png)
   >
   > `Failed to fetch 接 404 错误`
   >
   > 又试了下 java 11, 结果畅通无阻😅
   >
   > ![image-20211024192048679](http://cdn.ayusummer233.top/img/202110241920778.png)
   >
   > Java 11 是 Java 的一个长期支持版本（LTS）。它同时也是 Ubuntu 20.04的默认 Java 开发和运行环境。
   >
   > Java 8，前一个 Java LTS 版本，目前仍被广泛应用。
   >
   > 更新下源
   >
   > ```shell
   > apt update
   > ```
   >
   > ![image-20211024192347636](http://cdn.ayusummer233.top/img/202110241923871.png)
   >
   > 再使用如下命令安装 java 8 ,然后成功了😅
   >
   > ```shell
   > apt install openjdk-8-jdk
   > ```
   >
   > ![image-20211024192700851](http://cdn.ayusummer233.top/img/202110241927959.png)
   >
   > 那么此时我的 `ubuntu 20.04` 中有两个 java, 编译 Hadoop 需要 Java 8, 当前默认的是 java 11, 所以需要更改默认版本
   >
   > ```shell
   > sudo update-alternatives --config java
   > ```
   >
   > ![image-20211024193029622](http://cdn.ayusummer233.top/img/202110241930723.png)
   >
   > ![image-20211024193457195](http://cdn.ayusummer233.top/img/202110241934341.png)

   在一些 Java 应用中, 环境变量 `JAVA_HOME` 被用来表示 Java 安装位置

   上一步中使用 `sudo update-alternatives --config java` 看到了各版本 java 的安装位置

   ```shell
     Selection    Path                                            Priority   Status
   ------------------------------------------------------------
     0            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      auto mode
     1            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      manual mode
   * 2            /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java   1081      manual mode
   ```

   然后打开 `/etc/environment` 文件添加 `JAVA_HOME`

   ![image-20211024194431375](http://cdn.ayusummer233.top/img/202110241944436.png)

   重载环境变量

   ```shell
   source /etc/environment
   ```

   查看 `JAVA_HOME` 生效情况

   ```shell
   echo $JAVA_HOME
   ```

   ![image-20211024194542257](http://cdn.ayusummer233.top/img/202110241945329.png)

   > [如何在 Ubuntu 20.04 上安装 Java - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/137114682)
   >
   > 可以使用 `apt remove` 命令卸载相应版本 java

---

2. SSH 必须安装

![image-20211024195027098](http://cdn.ayusummer233.top/img/202110241950309.png)

---

### 安装软件

安装 `ssh` 和 `pdsh`

```shell
sudo apt-get install ssh
sudo apt-get install pdsh
```

> ![image-20211024195241497](http://cdn.ayusummer233.top/img/202110241952019.png)
>
> ![image-20211024195311555](http://cdn.ayusummer233.top/img/202110241953340.png)

---

## 下载

从[Index of /hadoop/common/hadoop-3.3.1 (apache.org)](https://dlcdn.apache.org/hadoop/common/hadoop-3.3.1/)获取稳定的发行版

![image-20211024200422270](http://cdn.ayusummer233.top/img/202110242004180.png)

AArch64 是 ARMv8 的一种执行状态

本地电脑是 amd64 架构的, 不能用那个包

![image-20211024200916933](http://cdn.ayusummer233.top/img/202110242012238.png)

> [【CPU】关于x86、x86_64/x64、amd64和arm64/aarch64 - 简书 (jianshu.com)](https://www.jianshu.com/p/2753c45af9bf)

> 打算放到 `root/Hadoop` 目录下:
>
> ![image-20211024201716352](http://cdn.ayusummer233.top/img/202110242017511.png)
>
> IDM 还挺快的, 不过速度基本维持在 1M 左右, 直接使用 `wget` 命令从文件地址下载倒快了很多
>
> ![image-20211024201843596](http://cdn.ayusummer233.top/img/202110242018666.png)

---

## 准备启动 Hadoop Cluster

解压缩下载的压缩包

```shell
tar -xf hadoop-3.3.1.tar.gz
```

> ![image-20211024202357274](http://cdn.ayusummer233.top/img/202110242023871.png)

打开解压后的文件夹中的 `etc/hadoop/hadoop-env.sh` 文件, 定义如下参数:

```shell
 # set to the root of your Java installation
 export JAVA_HOME=/usr/java/latest
```

其实[上一步](#需要安装的软件)已经设置了环境变量 JAVA_HOME, 不过在这里设定为项目参数的话也可以

![image-20211024213941363](http://cdn.ayusummer233.top/img/202110242139488.png)

`cd` 到解压缩文件夹根目录再执行 `bin/hadoop`

```shell
cd Hadoop/hadoop-3.3.1
bin/hadoop
```

![image-20211024214152222](http://cdn.ayusummer233.top/img/202110242141351.png)

可以看到 Hadoop 的使用文档

到此为止已经准备好了在三种支持模式之一启动 Hadoop Cluster

- [本地(独立)模式  Local (Standalone) Mode](#独立操作)
- [伪分布模式  Pseudo-Distributed Mode](#伪分布式操作)
- [全分布式模式 Fully-Distributed Mode](#全分布式操作)

---

## 独立操作

默认情况下, Hadoop 被配置为以 non-distributed 模式运行, 作为单个 java 进程. 这样调试比较方便

---

## 伪分布式操作

Hadoop 可以在单节点上以一种伪分布式的模式运行, 其中每个 Hadoop daemon 以一个单独的 java 进程运行

---

### 配置

使用如下配置文件:

`etc/Hadoop/core-site.xml`

```xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
</configuration>
```

![image-20211024221117826](http://cdn.ayusummer233.top/img/202110242211948.png)

`etc/hadoop/hdfs-site.xml`

```xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
</configuration>
```

![image-20211024221228547](http://cdn.ayusummer233.top/img/202110242212529.png)

---

### 配置无密码 SSH

现在检查下是否可以不用密码 ssh 上 localhost

```shell
ssh localhost
```

> 如果提示需要密码继续执行的话可以如下配置:
>
> ```shell
> ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
> cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
> chmod 0600 ~/.ssh/authorized_keys
> ```
>
> ---
>
> `ssh: connect to host localhost port 22: Connection refused）`
>
> [wsl 的 ssh server 无法启动 （ssh localhost 时报错ssh: connect to host localhost port 22: Connection refused）_hxc2101的博客-CSDN博客](https://blog.csdn.net/hxc2101/article/details/113617870)
>
> 打开 `/etc/ssh/sshd_config` 将监听地址 localhost 取消注释:
>
> ![image-20211026214222894](http://cdn.ayusummer233.top/img/202110262142078.png)
>
> 然后 
>
> ```shell
> service ssh restart
> ```
>
> > **mark 下这句 ssh 服务重启指令**, ssh localhost 能够正常运行后如果 WSL2 关闭重启了再 `ssh localhost` 可能还会 `Connection refused`, 这时只要再 `service ssh restart` 然后 `ssh localhost` 就可以了
> >
> > ![image-20211026214857109](http://cdn.ayusummer233.top/img/202110262148965.png)
>
> ---
>
> ![image-20211025131945538](http://cdn.ayusummer233.top/img/202110251319717.png)
>
> [Error(15) 解决 sshd: no hostkeys available -- exiting._郑清-CSDN博客](https://blog.csdn.net/qq_38225558/article/details/117793432)
>
> ```sh
> ssh-keygen -A
> /etc/init.d/ssh start
> ssh localhost
> ```
>
> 
>
> ![image-20211025132104948](http://cdn.ayusummer233.top/img/202110251321020.png)



![image-20211025125804673](http://cdn.ayusummer233.top/img/202110251258396.png)

---

### 执行

以下是本地运行 MapReduce 作业

#### 1.格式化文件系统

在 Hadoop 解压文件夹根目录下运行

```shell
bin/hdfs namenode -format
```

![image-20211024222114432](http://cdn.ayusummer233.top/img/202110242221127.png)

![image-20211024222152831](http://cdn.ayusummer233.top/img/202110242221957.png)

---

#### 2.启动 NameNode daemon 和 DataNode daemon

```shell
sbin/start-dfs.sh
```

![image-20211024222740643](http://cdn.ayusummer233.top/img/202110242227516.png)

> `ERROR: Attempting to operate on hdfs namenode as root`
>
> [Hadoop单点安装FAQ_WuTing的专栏-CSDN博客_hadoop单点安装](https://blog.csdn.net/u013725455/article/details/70147331)
>
> 编辑 `start-dfs.sh` 和 `stop-dfs.sh`
>
> ```shell
> HDFS_DATANODE_USER=root
> HADOOP_SECURE_DN_USER=hdfs
> HDFS_NAMENODE_USER=root
> HDFS_SECONDARYNAMENODE_USER=root
> ```
>
> ![image-20211025120547517](http://cdn.ayusummer233.top/img/202110251205702.png)
>
> ![image-20211025120615732](http://cdn.ayusummer233.top/img/202110251206850.png)
>
> 编辑 `start-yarn.sh` 和 `stop-yarn.sh`
>
> ```shell
> YARN_RESOURCEMANAGER_USER=root
> HADOOP_SECURE_DN_USER=yarn
> YARN_NODEMANAGER_USER=root
> ```
>
> ![image-20211025120659391](http://cdn.ayusummer233.top/img/202110251206482.png)
>
> ![image-20211025120709151](http://cdn.ayusummer233.top/img/202110251207240.png)
>
> 修改完后再次启动 `NameNode` 和 `DataNode`:
>
> ```shell
> sbin/start-dfs.sh
> ```
>
> ---
>
> `pdsh@xxxx: localhost: connect: Connection refused`
>
> [pdsh@xxxx: localhost: connect: Connection refused_PubliclyAccessible的博客-CSDN博客](https://blog.csdn.net/PubliclyAccessible/article/details/103910041)
>
>  ```shell
> export PDSH_RCMD_TYPE=ssh
>  ```
>  
>  ![image-20211025132339387](http://cdn.ayusummer233.top/img/202110251323690.png)
> 

启动 `resourceManager` 然后访问 `localhost:8088` 就可以看到管理界面了:

```shell
sbin/yarn.sh
localhost:8088
```

> ![image-20211025132450858](http://cdn.ayusummer233.top/img/202110251324120.png)


---

### 单个节点上的 YARN

略

---

## 全分布式操作

略

